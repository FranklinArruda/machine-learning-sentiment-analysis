





# Importing libraries
import pandas as pd
import numpy as np





# Loading the dataset (BankRecords.csv)
df = pd.read_csv(r"C:\Users\STUDENT\Desktop\ML-CA2-50\BankRecords.csv")





# Checking shape of the dataset to understand the size
print("\nDataset Shape:")
print(df.shape) 





# Displaying a sample of the dataset
print("\nSample of the Data:")
print(df.head())  








# Checking data types and overall structure

print("\nData Types and Memory Usage:")
df_info = df.info()  # Checking data types and memory usage here...
print(df_info)





# Checking for missing values in each column this time
print("\nMissing Values:")
missing_values = df.isnull().sum()
print(missing_values)





print("\nDropping the 'ID' column...")
df.drop(columns=['ID'], inplace=True)





print("\nData after dropping 'ID':")
print(df.head())





binary_cols = ['Personal Loan', 'Securities Account', 'CD Account', 'Online Banking', 'CreditCard']
df[binary_cols] = df[binary_cols].replace({'No': 0, 'Yes': 1}).astype(int)





print("\nSample of Binary Encoding:")
print(df[binary_cols].head())





print("\nUnique Values in 'Education':")
print(df['Education'].value_counts())

# I changed the 'Education' column into new columns with numbers. 
# Each new column is for one type of education. 
# I used drop_first=True so I donâ€™t repeat the same info.
df = pd.get_dummies(df, columns=['Education'], drop_first=False)





education_cols = [col for col in df.columns if 'Education_' in col]
df[education_cols] = df[education_cols].astype(int)





# Verifying the one-hot encoding
print("\nData after One-Hot Encoding 'Education':")
print(df.head())


# Printing all shape 
print("\nDataset Shape After Encoding and Cleaning:")
print(df.shape)


# Printing the columns 
print("\nColumns After One-Hot Encoding:")
print(df.columns)





print("\nChecking for Missing Values After Cleanup:")
print(df.isnull().sum())








# imports
from sklearn.model_selection import train_test_split

# Splitting the data into features (X) and target (y)
# X is everything except the target column, y is just the target column
X = df.drop(columns=["Income(Thousands's)"])  
y = df["Income(Thousands's)"]  





# Using 80% of the data for training and 20% for testing as good practice, which is pretty standard
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)





# Printing them
print("\nTraining Features Shape:", X_train.shape)
print("Testing Features Shape:", X_test.shape)
print("Training Target Shape:", y_train.shape)
print("Testing Target Shape:", y_test.shape)








# The distribution of the target variable
import matplotlib.pyplot as plt
plt.hist(y_train, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
plt.title("Distribution of Training Target (Income)")
plt.xlabel("Income (Thousands)")
plt.ylabel("Frequency")
plt.show()








!pip install tensorflow


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Defining the models
model = Sequential()






# Input layer and first hidden layer
model.add(Dense(units=64, input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(0.3))







# Second hidden layer
model.add(Dense(units=32, activation='relu'))
model.add(Dropout(0.3))

# Third hidden layer
model.add(Dense(units=16, activation='relu'))
model.add(Dropout(0.3))

# Output layer (single node for regression)
model.add(Dense(units=1, activation='linear'))

# Compiling the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Model summary for a quick check
model.summary()







